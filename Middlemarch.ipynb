{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jungyoonlim/middlemarch/blob/main/Middlemarch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzIeOqBHBPif"
      },
      "source": [
        " **Middlemarch Project.**\n",
        "\n",
        "Objective: Break down George Eliot's Middlemarch into relevant story metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "SbZYVJjGAY_m",
        "outputId": "73536e54-d5f0-4e33-b247-e3858858af84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-52de3a7e-569a-4b57-abce-f843a2768f3a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-52de3a7e-569a-4b57-abce-f843a2768f3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSYWGQyX6Z3_",
        "outputId": "4756e199-d881-4531-e573-d1107a91b6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "file_path = 'middlemarch.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    middlemarch_text = file.read()\n",
        "\n",
        "print(\"Text loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfTcEG7pAk0V",
        "outputId": "d4a864fb-d86d-4ae1-ce7e-7a83e13a7ff5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 11900\n",
            "Number of words: 370620\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Assuming 'middlemarch_text' contains the entire text of Middlemarch\n",
        "\n",
        "# Step 1: Remove Gutenberg Headers and Footers\n",
        "# The headers/footers vary, but often include phrases like \"Project Gutenberg\"\n",
        "start_marker = \"PRELUDE.\"\n",
        "end_marker = \"THE END\"\n",
        "\n",
        "start = middlemarch_text.find(start_marker)\n",
        "end = middlemarch_text.find(end_marker)\n",
        "\n",
        "# Extract only the main text\n",
        "main_text = middlemarch_text[start:end]\n",
        "\n",
        "# Step 2: Tokenization\n",
        "# Split into sentences\n",
        "sentences = sent_tokenize(main_text)\n",
        "\n",
        "# Split into words\n",
        "words = word_tokenize(main_text)\n",
        "\n",
        "print(f\"Number of sentences: {len(sentences)}\")\n",
        "print(f\"Number of words: {len(words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSjp7kknIGdY"
      },
      "source": [
        "Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Pt6IqtCbof",
        "outputId": "f4416785-da8d-468f-a824-d954b4fed3e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edward Casaubon\n",
            "Humphrey\n",
            "Wrench\n",
            "Gog\n",
            "Lowick Manor\n",
            "Cranch\n",
            "delight,—which\n",
            "Der\n",
            "Oliver\n",
            "Mengan\n",
            "Baldwin\n",
            "Christy\n",
            "Que de voir d’héritiers\n",
            "SHAKESPEARE\n",
            "Edinburgh\n",
            "findeth\n",
            "Will\n",
            "Ladislaw\n",
            "Spanning\n",
            "Adolf\n",
            "Fred felt\n",
            "Henrietta Noble\n",
            "John Milton\n",
            "Briggs\n",
            "Mizraim\n",
            "Mrs Cadwallader\n",
            "Lyons\n",
            "Mythologies\n",
            "Lydgate\n",
            "Ware\n",
            "Simmons\n",
            "Waverley\n",
            "Chichely\n",
            "Philémon\n",
            "Finer\n",
            "Walter Scott\n",
            "Robert\n",
            "Taft\n",
            "Adam\n",
            "aimés dès\n",
            "Lucy\n",
            "Glasgow\n",
            "Laura\n",
            "Mrs Dollop\n",
            "emphatically,—“she\n",
            "Thrice\n",
            "Solomon\n",
            "Henry V\n",
            "Keck\n",
            "Peel\n",
            "Rectory\n",
            "Vicar\n",
            "Fred and Mary\n",
            "Balstrode\n",
            "”—GUIZOT\n",
            "Nancy Nash\n",
            "Miss Farebrother\n",
            "Ellen\n",
            "Implacable\n",
            "Lowick\n",
            "Limp\n",
            "Mary re-\n",
            "Laennec\n",
            "Bulstrode\n",
            "Library\n",
            "Jove\n",
            "Hiram Ford\n",
            "Mary saw Fred\n",
            "messenger\n",
            "awaken\n",
            "Rigg Featherstone\n",
            "Fred forsaken\n",
            "Pseudodoxia Epidemica\n",
            "Sprague\n",
            "Pippin\n",
            "Vuol la sua stagione\n",
            "half nymph\n",
            "Mordaunt Merton\n",
            "Dill\n",
            "Dorothea’s\n",
            "Ba-Lamb\n",
            "Leeds\n",
            "Rembrandt\n",
            "Bill\n",
            "Despond\n",
            "Fitchett\n",
            "Sappho\n",
            "Mozart\n",
            "Joanna\n",
            "nosotros viene sobre\n",
            "John\n",
            "Jonas\n",
            "Peacock\n",
            "rick\n",
            "Bob\n",
            "Sophia Primrose\n",
            "Winifred\n",
            "Callum\n",
            "Resolve\n",
            "Peter\n",
            "Featherstone\n",
            "Dodo\n",
            "Fred Vincy’s\n",
            "Green Dragon\n",
            "Mary\n",
            "Reason\n",
            "Will Ladislaw’s\n",
            "Enmity\n",
            "Eros\n",
            "L. E. L.” Rosamond\n",
            "Timothy\n",
            "Cooper\n",
            "Sister Martha\n",
            "Burke\n",
            "poets,—in\n",
            "Rosy\n",
            "Brooke of\n",
            "Broussais\n",
            "Julia\n",
            "Caius Larcher\n",
            "Meleager\n",
            "Charles James Fox\n",
            "Whate’er\n",
            "Fred’s\n",
            "Marlowe\n",
            "Call Fred Vincy\n",
            "Joshua Rigg’s\n",
            "Crowner\n",
            "Cruelty\n",
            "Rambler\n",
            "Clara\n",
            "Harfager\n",
            "CHARLES\n",
            "Spicer\n",
            "Miss\n",
            "Brooke\n",
            "Robert Brown’s\n",
            "Horrock\n",
            "Adventures\n",
            "Cleopatra\n",
            "Scott\n",
            "marry Rosamond\n",
            "Augustine\n",
            "Clown\n",
            "Orlando Ladislaw\n",
            "Chus\n",
            "Ellen Bulstrode\n",
            "Theresa\n",
            "Hopkins\n",
            "Worthy\n",
            "Voltaire\n",
            "Carter\n",
            "Latimer\n",
            "Bretton\n",
            "Nancy\n",
            "Providence\n",
            "Henry VIII\n",
            "Charles\n",
            "Earl\n",
            "Sophy\n",
            "Antichrist\n",
            "Diamond\n",
            "Dagley\n",
            "Garths\n",
            "La Vita\n",
            "Evan Dhu\n",
            "Frank Hawley\n",
            "Tucker\n",
            "Wrong\n",
            "Juliet\n",
            "Fred\n",
            "Vincy\n",
            "de lait_\n",
            "Robisson\n",
            "Susan\n",
            "Whig\n",
            "Quickness\n",
            "Arthur\n",
            "Joseph\n",
            "queramos aquello\n",
            "que\n",
            "podremos\n",
            "Jane Featherstone\n",
            "Fred for Mary\n",
            "omne\n",
            "Ken\n",
            "Worthies\n",
            "Jacob\n",
            "Sarah Dunkirk\n",
            "Morgan\n",
            "Martha\n",
            "Levant\n",
            "Beauty\n",
            "Cam\n",
            "Timothy\n",
            "Waule\n",
            "Bowyer\n",
            "Pope\n",
            "Malice\n",
            "Thesiger\n",
            "Diana\n",
            "Zum höchsten Dasein\n",
            "Juvenal\n",
            "Southey\n",
            "Vincys\n",
            "Purgatorio\n",
            "Guido\n",
            "Bedlam\n",
            "Casaubon\n",
            "Guydo\n",
            "Lowick Parish\n",
            "basil\n",
            "Miss Noble\n",
            "Miss Winifred\n",
            "Farebrother\n",
            "Mangnall\n",
            "Live\n",
            "Larcher\n",
            "Althorpe\n",
            "Newgate\n",
            "Dover\n",
            "Musophilus\n",
            "Healer\n",
            "Celia\n",
            "Levantine\n",
            "Fortune\n",
            "satin stocks\n",
            "Crabbe\n",
            "Gerveis\n",
            "brio\n",
            "Letty\n",
            "Lowick Dorothea\n",
            "Luck\n",
            "Parnassus\n",
            "James Chettam’s\n",
            "Jonah Featherstone\n",
            "Chatham\n",
            "Pitt\n",
            "Bam\n",
            "Ben\n",
            "Dantzic\n",
            "Gospel\n",
            "Ladislaw?—shall\n",
            "riddle?—it\n",
            "Abraham\n",
            "Jim\n",
            "Murder\n",
            "Tertius\n",
            "Madam\n",
            "Sarah\n",
            "Kell\n",
            "Chatterton\n",
            "Qui\n",
            "Yorkshire\n",
            "Blindman\n",
            "Lowick Parsonage\n",
            "BEN JONSON\n",
            "De Quincey’s\n",
            "guancia\n",
            "Della\n",
            "Coleman\n",
            "Joshua\n",
            "George\n",
            "Tempest\n",
            "Ian Vor\n",
            "Piozzi\n",
            "Kate\n",
            "Unto\n",
            "Freshitt\n",
            "head—“it\n",
            "Je reviendrais\n",
            "Beatrice\n",
            "Love\n",
            "Mrs Garth\n",
            "Fatigue\n",
            "Laure\n",
            "Mary a minute\n",
            "Lord Megatherium\n",
            "Beck\n",
            "Triton\n",
            "John Waule\n",
            "Tory\n",
            "BOOK I.\n",
            "MISS BROOKE\n",
            "Raphael\n",
            "Dagon\n",
            "Churchill\n",
            "Grange\n",
            "Liar\n",
            "Aristotle\n",
            "Farebrother\n",
            "Fred\n",
            "felt\n",
            "Webbe\n",
            "Garth\n",
            "Strype\n",
            "Virgil\n",
            "Dissenting hymn-books\n",
            "Heady\n",
            "Renfrew\n",
            "Kitty\n",
            "Standish\n",
            "Cadwallader\n",
            "mia donna Amore\n",
            "B.\n",
            "Parsonage\n",
            "Wimple\n",
            "Pratt\n",
            "Offenbach\n",
            "Lowick Gate\n",
            "Sister Jane\n",
            "Mary\n",
            "Garth\n",
            "Boguy\n",
            "BOOK V.\n",
            "THE DEAD\n",
            "Wright\n",
            "Blessed Virgin\n",
            "Josh\n",
            "Thomas\n",
            "Aquainas\n",
            "Muster Garth\n",
            "Edward\n",
            "Huskisson\n",
            "Garratt\n",
            "Fuggon\n",
            "Leonard Lamb\n",
            "Lunnon\n",
            "Hiram Ford’s\n",
            "ALFRED DE MUSSET\n",
            "Froth\n",
            "Satire\n",
            "Goby\n",
            "Houndsley\n",
            "Young Ladislaw\n",
            "Frick\n",
            "Archie Duncan\n",
            "Lady Blessington\n",
            "Overreach\n",
            "Bott\n",
            "Blucher\n",
            "Godwin\n",
            "Tollers\n",
            "Young\n",
            "Ladislaw\n",
            "Ariadne\n",
            "Philomicron\n",
            "Mist\n",
            "Aunt Julia\n",
            "Adam Smith\n",
            "Lemon\n",
            "Caleb\n",
            "CHAPTER V.\n",
            "Monk\n",
            "Chairman\n",
            "Walter Tyke\n",
            "Shelley\n",
            "Fred and Rosamond\n",
            "Freke\n",
            "John Raffles\n",
            "Vyan\n",
            "said—“Heaven\n",
            "L’homme qui rit\n",
            "Majesty\n",
            "George the Fourth\n",
            "Thomas\n",
            "Browne\n",
            "Affectionate\n",
            "Gambit\n",
            "Jonah\n",
            "meinen Füssen\n",
            "Clintup\n",
            "Blakesley\n",
            "Bunney\n",
            "Loo\n",
            "Spilkins\n",
            "Divine Providence\n",
            "Corydon\n",
            "Sally\n",
            "Bat\n",
            "Thoth\n",
            "Horace\n",
            "Mawmsey\n",
            "Miss Brooke’s\n",
            "Maid\n",
            "Edwin Larcher\n",
            "Harriet Vincy\n",
            "Bunyan\n",
            "Warburton\n",
            "now!—he\n",
            "Mr Casaubon\n",
            "Ballard\n",
            "Featherstone\n",
            "Churchyard Lane\n",
            "divin qui\n",
            "Presently Rosamond\n",
            "John Long\n",
            "Godwin Lydgate\n",
            "Cholera\n",
            "buff\n",
            "John Bull\n",
            "Puritanic\n",
            "Johnson\n",
            "Ladislaw\n",
            "Harry Toller\n",
            "Arabella Hawley\n",
            "Rigg\n",
            "Tantripp\n",
            "Powderell\n",
            "Raspail\n",
            "Jew\n",
            "Freshitt Hall\n",
            "Vesalius\n",
            "BEAUMONT\n",
            "Frederic\n",
            "Miss Morgan\n",
            "Tom Toller\n",
            "Dollop\n",
            "Dante\n",
            "Don\n",
            "Chettam\n",
            "Nicholas\n",
            "Bulstrode\n",
            "Cressida\n",
            "Mr Brooke\n",
            "Cadwallader—“when\n",
            "Si\n",
            "Lowick Rectory\n",
            "Minchin\n",
            "Hitherto\n",
            "Job\n",
            "Caleb Garth\n",
            "Peter\n",
            "CHAPTER L.\n",
            "Letty Garth\n",
            "Alfred\n",
            "Nimrod\n",
            "Miss Vincy\n",
            "Mix\n",
            "Cheshire\n",
            "Waldenses\n",
            "Tis\n",
            "Will\n",
            "Samuel’s\n",
            "Thou\n",
            "Raffles\n",
            "Daylesford\n",
            "Jack\n",
            "Trumbull\n",
            "Miss Brooke\n",
            "Exemplary\n",
            "Beschliessen\n",
            "C’est de Daphnis\n",
            "Hawley\n",
            "Shallow\n",
            "Riverston\n",
            "Tamburlaine\n",
            "Cheltenham\n",
            "Aunt Bulstrode\n",
            "jamais rien\n",
            "Edward Thesiger\n",
            "Peg\n",
            "Lowick Cicero\n",
            "Henry VI\n",
            "Ode to Duty\n",
            "Michaelmas\n",
            "London Dissenter\n",
            "S.\n",
            "Tom\n",
            "Manor\n",
            "comme\n",
            "Young Hawley\n",
            "que queremos\n",
            "Hiram\n",
            "Paracelsus\n",
            "Tyke\n",
            "Ariel\n",
            "Willoughby\n",
            "Harry\n",
            "Faulkner\n",
            "Petrarch\n",
            "Will Ladislaw\n",
            "Lucifer\n",
            "Young\n",
            "Lowth\n",
            "Ned Plymdale\n",
            "Hackbutt\n",
            "James\n",
            "Chettam\n",
            "Monsieur Liret\n",
            "Muse\n",
            "Mary Garth\n",
            "Judy\n",
            "Hanmer\n",
            "Mamma\n",
            "Vincy\n",
            "marquis\n",
            "Frank\n",
            "Hawley\n",
            "Jeremy Taylor\n",
            "Jane Waule\n",
            "tête-à-tête\n",
            "Clo\n",
            "John Russell\n",
            "Le Légataire\n",
            "Camden Farebrother\n",
            "I. ‘He’s\n",
            "Thumb\n",
            "Godwin Lydgate’s\n",
            "HENRY WOTTON\n",
            "Jeersteen\n",
            "Cheap Jack\n",
            "Grampus\n",
            "Porson\n",
            "a Servile Crawler\n",
            "Nicholas\n",
            "l’aube de la\n",
            "Cush\n",
            "Romance\n",
            "Avila\n",
            "Dunkirk\n",
            "Hanged\n",
            "Nicholas Bulstrode\n",
            "Vaudois\n",
            "Majesty George\n",
            "Flora MacIvor\n",
            "&c.\n",
            "Vigo\n",
            "Fred\n",
            "Lady\n",
            "Chettam\n",
            "George the Third\n",
            "Nacht\n",
            "Minna\n",
            "Nick\n",
            "rick-thatcher\n",
            "Rosamond\n",
            "Vincy\n",
            "Prayer\n",
            "Milton\n",
            "Circumstance\n",
            "Miss Rosamond\n",
            "James’s\n",
            "qui se\n",
            "Toward Walter Scott\n",
            "Sophy Toller\n",
            "Schön\n",
            "Louisa\n",
            "Eve\n",
            "Aquinas\n",
            "Solomon\n",
            "Featherstone\n",
            "Abel\n",
            "Solomon Featherstone\n",
            "Hush\n",
            "Toller\n",
            "Dorothea Brooke\n",
            "Peter Featherstone\n",
            "Herschel\n",
            "Mademoiselle de Montmorenci\n",
            "Waterloo\n",
            "Italian Proverb\n",
            "Lawyer Standish\n",
            "Borthrop Trumbull\n",
            "Mammon\n",
            "Gypsy\n",
            "Slaughter Lane\n",
            "Geistlicher\n",
            "James\n",
            "Elinor\n",
            "Stubbs\n",
            "Tegg\n",
            "Brooke\n",
            "Joshua Rigg\n",
            "Killjoy\n",
            "Dagleys\n",
            "Lindley Murray\n",
            "Happily Dorothea\n",
            "Croly\n",
            "Fad\n",
            "Mary—don’t\n",
            "Rosamond\n",
            "DONNE\n",
            "Lord Grey\n",
            "Teveroy\n",
            "Thomas Aquinas\n",
            "coeur se donne\n",
            "Crabsley\n",
            "Isaiah\n",
            "God\n",
            "Churchman\n",
            "Beevor\n",
            "Ned\n",
            "Brenda Troil\n",
            "Poste Restante\n",
            "Africay\n",
            "qui vive\n",
            "James Chettam\n",
            "Damme\n",
            "Wakley\n",
            "Brasenose\n",
            "Walter\n",
            "Wrenches\n",
            "Fred Vincy\n",
            "Miss Winifred\n",
            "Mary to-day\n",
            "Apocalypse\n",
            "Truberry\n",
            "Tim\n",
            "Kit Downes\n",
            "Happily Rosamond\n",
            "King James\n",
            "Lady Chettam\n",
            "Peter Featherstone’s\n",
            "Naumann\n",
            "marry\n",
            "Apollos\n",
            "Elizabeth\n",
            "Madonna\n",
            "Canterbury Tales\n",
            "Dorothea\n",
            "Magog\n",
            "people,—no\n",
            "Adolf Naumann\n",
            "Harriet\n",
            "Jane\n",
            "Hate\n",
            "Bambridge\n",
            "St.\n",
            "Galen\n",
            "Mary Garth’s\n",
            "Thy\n",
            "Keble\n",
            "Brookes\n",
            "Tan\n",
            "Chettams\n",
            "Grainger\n",
            "Crowse\n",
            "Pascal\n",
            "Byles\n",
            "Noble\n",
            "Saint Catherine\n",
            "Caleb\n",
            "Garth\n",
            "Joshua Rigg Featherstone\n",
            "Warren Hastings\n",
            "Godwin\n",
            "Lydgate\n",
            "Plymdale\n",
            "Casaubon?—if\n",
            "Bruce\n",
            "Bailey\n",
            "Pegasus\n",
            "Bouddha\n",
            "Trapping Bass\n",
            "Dorothea rang\n",
            "l’ignorance de\n",
            "la\n",
            "Grey\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = len(main_text)\n",
        "doc = nlp(main_text)\n",
        "\n",
        "character_entities = set()\n",
        "\n",
        "for entity in doc.ents:\n",
        "  if entity.label_ == 'PERSON':\n",
        "    if not any(char.isdigit() for char in entity.text):\n",
        "      character_entities.add(entity.text.strip())\n",
        "\n",
        "for character in character_entities:\n",
        "  print(character)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUDaN1iTIB24",
        "outputId": "9997b41f-0871-4670-ce72-711598f14ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=0.0, subjectivity=0.0)\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "sentence = TextBlob(sentences[0])\n",
        "print(sentence.sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv7ETFz9ITwl"
      },
      "source": [
        "Summary Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGVKkWRgKIED",
        "outputId": "9e9ed632-a1c2-44db-e863-f912bd8c2fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.31.0)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (23.12.7)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install sumy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t77XOfeTRzXj"
      },
      "source": [
        "Topic Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQBcUJGGShWh"
      },
      "source": [
        "Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z52avIedXtFU"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3lVOn2zeXxJc",
        "outputId": "22099ce5-b520-4d2f-d61a-57ccb88af232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TextRankSummarizer:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-a0793d7cbaab>\", line 16, in <cell line: 14>\n",
            "    for sentence in summarizer(parser.document, num_sentences_summary):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\", line 40, in __call__\n",
            "    ratings = self.rate_sentences(document)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\", line 49, in rate_sentences\n",
            "    matrix = self._create_matrix(document)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\", line 69, in _create_matrix\n",
            "    rating = self._rate_sentences_edge(words_i, sentences_as_words[j])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\", line 89, in _rate_sentences_edge\n",
            "    rank = sum(words2.count(w) for w in words1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\", line 89, in <genexpr>\n",
            "    rank = sum(words2.count(w) for w in words1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 817, in getsourcefile\n",
            "    filename = getfile(object)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/package/package_importer.py\", line 693, in _patched_getfile\n",
            "    if inspect.isclass(object):\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 191, in isclass\n",
            "    def isclass(object):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a0793d7cbaab>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarizer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sentences_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, document, sentences_count)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36mrate_sentences\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m_create_matrix\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_sentences_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_as_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m_rate_sentences_edge\u001b[0;34m(words1, words2)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_rate_sentences_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_rate_sentences_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "num_sentences_summary = 10\n",
        "\n",
        "parser = PlaintextParser.from_string(main_text, Tokenizer(\"english\"))\n",
        "summarizer_list=(\"TextRankSummarizer:\",\"LexRankSummarizer:\",\"LuhnSummarizer:\",\"LsaSummarizer\") #list of summarizers\n",
        "summarizers = [TextRankSummarizer(), LexRankSummarizer(), LuhnSummarizer(), LsaSummarizer()]\n",
        "\n",
        "for i, summarizer in enumerate(summarizers):\n",
        "  print(summarizer_list[i])\n",
        "  for sentence in summarizer(parser.document, num_sentences_summary):\n",
        "    print(sentence)\n",
        "  print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tygRdKEbbXhF"
      },
      "source": [
        "Topic Modeling\n",
        "\n",
        "- Preprocess and Tokenize the Text\n",
        "- Create Dictionary and Corpus\n",
        "- LDA for Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "r-r65geqbXAt",
        "outputId": "918b7574-fabd-4016-c2c1-13efa4cb0bf8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-27b58d64dcef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
          ]
        }
      ],
      "source": [
        "processed_text = preprocess(main_text)\n",
        "\n",
        "print(processed_text[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kppwYGNida_c",
        "outputId": "31ffd597-34f4-4f37-c80c-6622df2a9c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chapters found: 86\n",
            "Start of chapter 1: Since I can do no good because a woman,\n",
            "Reach constantly at something that is near it.\n",
            "             \n",
            "Start of chapter 2: “‘Dime; no ves aquel caballero que hacia nosotros viene sobre un\n",
            "caballo rucio rodado que trae puest\n",
            "Start of chapter 3: “Say, goddess, what ensued, when Raphael,\n",
            "The affable archangel . . .\n",
            "                    Eve\n",
            "The st\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "# Adjust the regular expression to match the chapter pattern exactly\n",
        "chapter_pattern = r'\\nCHAPTER [IVXLCDM]+\\.'  # This includes the newline character and period\n",
        "\n",
        "# Use re.split to split the text into chapters\n",
        "chapters = re.split(chapter_pattern, main_text)\n",
        "\n",
        "chapters = chapters[1:]\n",
        "\n",
        "# Filter out any empty strings that might have been created during the split\n",
        "chapters = [chapter.strip() for chapter in chapters if chapter.strip()]\n",
        "\n",
        "print(f\"Total chapters found: {len(chapters)}\")\n",
        "for i in range(3):\n",
        "    print(f\"Start of chapter {i+1}: {chapters[i][:100]}\")  # Preview first 100 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "fwKMjxxibCy9",
        "outputId": "32302fd6-07b2-416a-f855-557e6b6c7442"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-dcd51212c1c3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_extremes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_below\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_above\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'processed_text' is not defined"
          ]
        }
      ],
      "source": [
        "from gensim.corpora import Dictionary\n",
        "\n",
        "dictionary = Dictionary([main_])\n",
        "\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.7, keep_n=50000)\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in [processed_text]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z29ZuEFmfs2H"
      },
      "source": [
        "\n",
        "Fine-Tune Models\n",
        "- Narrative Generation and Understanding\n",
        "- Custom NER Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7nlFXWzgk8P",
        "outputId": "fa21a64a-c523-416b-914d-a4a48795f794"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ9l30-whrue",
        "outputId": "fd7c389b-8d14-4ac4-edec-e1b211cfc92f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'score': 0.037618719041347504, 'token': 4300, 'token_str': 'arthur', 'sequence': 'the main character in middlemarch is arthur.'}\n",
            "{'score': 0.013670222833752632, 'token': 2848, 'token_str': 'peter', 'sequence': 'the main character in middlemarch is peter.'}\n",
            "{'score': 0.013061015866696835, 'token': 2852, 'token_str': 'dr', 'sequence': 'the main character in middlemarch is dr.'}\n",
            "{'score': 0.011167364194989204, 'token': 17001, 'token_str': 'sgt', 'sequence': 'the main character in middlemarch is sgt.'}\n",
            "{'score': 0.009783466346561909, 'token': 2198, 'token_str': 'john', 'sequence': 'the main character in middlemarch is john.'}\n"
          ]
        }
      ],
      "source": [
        "fill_mask_pipe = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "\n",
        "# Example usage\n",
        "masked_text = \"The main character in Middlemarch is [MASK].\"\n",
        "predictions = fill_mask_pipe(masked_text)\n",
        "\n",
        "for prediction in predictions:\n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "5t_uuhbqmQNz",
        "outputId": "5050a823-5fc2-4319-bae7-a45050637090"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f3b18992076d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmiddlemarch_paragraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmiddlemarch_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming two newlines separate paragraphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'middlemarch_text' is not defined"
          ]
        }
      ],
      "source": [
        "middlemarch_paragraphs = middlemarch_text.split('\\n\\n')  # Assuming two newlines separate paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "NYGl6OIvmJcF",
        "outputId": "37f453af-4a43-4ccd-ff6b-6263692f1c09"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b5631f278ed4>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create a dataset object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmiddlemarch_paragraphs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_data_to_model_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'middlemarch_paragraphs' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import BartTokenizer\n",
        "from datasets import Dataset\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    # Tokenize the inputs and labels\n",
        "    inputs = tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "    return inputs\n",
        "\n",
        "# Create a dataset object\n",
        "dataset = Dataset.from_dict({'text': middlemarch_paragraphs})\n",
        "dataset = dataset.map(process_data_to_model_inputs, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buK0t2wym9iy"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbdlnzLZqQQR"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch] -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tXd-7SLqSiT"
      },
      "outputs": [],
      "source": [
        "!pip install torch -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "qKcIJOMumgtF",
        "outputId": "f1916b08-8838-4d64-f543-5bb3e40ebd6d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-050a23f18f05>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43DjIynnmpna"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"./fine_tuned_bart\", tokenizer=tokenizer)\n",
        "\n",
        "generated_text = generator(\"Example prompt\", max_length=50)\n",
        "print(generated_text[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j91Qpugkgc08"
      },
      "source": [
        "Further Metadata Extraction\n",
        "- Character Relationships\n",
        "- Plot Analysis\n",
        "- Style and Tone Analysis"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMK6wjq7qsyTI+DfNtwcAee",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
